{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "279506bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: sumy in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: langdetect in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: docopt<0.7,>=0.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sumy) (0.6.2)\n",
      "Requirement already satisfied: breadability>=0.1.20 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sumy) (0.1.20)\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sumy) (2.29.0)\n",
      "Requirement already satisfied: pycountry>=18.2.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sumy) (24.6.1)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: chardet in c:\\users\\hp\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2023.5.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk sumy langdetect scikit-learn rouge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af8bd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from langdetect import detect\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, scrolledtext, Toplevel\n",
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        detected_lang = detect(text)  # Detect the language\n",
    "        stop_words = stopwords.words(detected_lang)  # Load stopwords\n",
    "    except:\n",
    "        detected_lang = 'english'  # Default to English if detection fails\n",
    "        stop_words = stopwords.words('english')\n",
    "    \n",
    "    words = nltk.word_tokenize(text.lower())  # Tokenize text\n",
    "    filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_words), detected_lang\n",
    "\n",
    "# Summarization Techniques\n",
    "def lsa_summarization(text, num_sentences=2):\n",
    "    preprocessed_text, detected_lang = preprocess_text(text)\n",
    "    parser = PlaintextParser.from_string(preprocessed_text, Tokenizer(detected_lang))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "    return ' '.join(str(sentence) for sentence in summary)\n",
    "\n",
    "def tfidf_summarization(text, num_sentences=2):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "    sentence_scores = np.array(tfidf_matrix.sum(axis=1)).ravel()\n",
    "    ranked_sentences = [sentences[i] for i in sentence_scores.argsort()[-num_sentences:][::-1]]\n",
    "    return ' '.join(ranked_sentences)\n",
    "\n",
    "def frequency_based_summarization(text, num_sentences=2):\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    freq = nltk.FreqDist(words)\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    ranked_sentences = sorted(sentences, key=lambda s: sum(freq[word.lower()] for word in nltk.word_tokenize(s)), reverse=True)\n",
    "    return ' '.join(ranked_sentences[:num_sentences])\n",
    "\n",
    "def length_based_summarization(text, num_sentences=2):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    ranked_sentences = sorted(sentences, key=len, reverse=True)\n",
    "    return ' '.join(ranked_sentences[:num_sentences])\n",
    "\n",
    "# GUI functions\n",
    "def summarize_text():\n",
    "    input_text = text_input.get(\"1.0\", tk.END).strip()\n",
    "    num_sentences = int(sentence_input.get())\n",
    "    \n",
    "    if not input_text:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please enter text to summarize.\")\n",
    "        return\n",
    "\n",
    "    selected_method = method_var.get()\n",
    "    \n",
    "    try:\n",
    "        if selected_method == \"LSA\":\n",
    "            summary = lsa_summarization(input_text, num_sentences)\n",
    "        elif selected_method == \"TF-IDF\":\n",
    "            summary = tfidf_summarization(input_text, num_sentences)\n",
    "        elif selected_method == \"Frequency-Based\":\n",
    "            summary = frequency_based_summarization(input_text, num_sentences)\n",
    "        elif selected_method == \"Length-Based\":\n",
    "            summary = length_based_summarization(input_text, num_sentences)\n",
    "\n",
    "        # Show the summary\n",
    "        text_output.delete('1.0', tk.END)  # Clear the output box\n",
    "        text_output.insert(tk.INSERT, f\"{selected_method} Summary:\\n{summary}\\n\\n\")\n",
    "\n",
    "        # Store the current summary\n",
    "        summaries[selected_method] = summary\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "def check_score():\n",
    "    selected_method = method_var.get()\n",
    "    if selected_method not in summaries:\n",
    "        messagebox.showwarning(\"Score Error\", \"Please summarize the text first before checking scores.\")\n",
    "        return\n",
    "    \n",
    "    reference_text = text_input.get(\"1.0\", tk.END).strip()\n",
    "    generated_summary = summaries[selected_method]\n",
    "    \n",
    "    # Calculate ROUGE score for the selected method\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(generated_summary, reference_text, avg=True)\n",
    "\n",
    "    # Show the score in a new window\n",
    "    score_window = Toplevel(root)\n",
    "    score_window.title(\"ROUGE Score\")\n",
    "\n",
    "    tk.Label(score_window, text=f\"{selected_method} ROUGE-1 F1 Score: {scores['rouge-1']['f']:.4f}\").pack(pady=5)\n",
    "    tk.Label(score_window, text=f\"{selected_method} ROUGE-2 F1 Score: {scores['rouge-2']['f']:.4f}\").pack(pady=5)\n",
    "    tk.Label(score_window, text=f\"{selected_method} ROUGE-L F1 Score: {scores['rouge-l']['f']:.4f}\").pack(pady=5)\n",
    "\n",
    "def compare_scores():\n",
    "    reference_text = text_input.get(\"1.0\", tk.END).strip()\n",
    "    if not reference_text:\n",
    "        messagebox.showwarning(\"Comparison Error\", \"Please enter text to compare scores.\")\n",
    "        return\n",
    "\n",
    "    selected_methods = [method for method in methods if method_var.get() == method]\n",
    "\n",
    "    if not selected_methods:\n",
    "        messagebox.showwarning(\"Comparison Error\", \"Please summarize the text using at least one method.\")\n",
    "        return\n",
    "\n",
    "    rouge = Rouge()\n",
    "    best_score = 0\n",
    "    best_method = \"\"\n",
    "\n",
    "    for method in selected_methods:\n",
    "        generated_summary = summaries.get(method, \"\")\n",
    "        if not generated_summary:\n",
    "            continue\n",
    "\n",
    "        scores = rouge.get_scores(generated_summary, reference_text, avg=True)\n",
    "        score = scores['rouge-1']['f']  # Using ROUGE-1 F1 score for comparison\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_method = method\n",
    "\n",
    "    # Show the best method and score\n",
    "    messagebox.showinfo(\"Best Method\", f\"The best method is {best_method} with a ROUGE-1 F1 Score of {best_score:.4f}\")\n",
    "\n",
    "# GUI Setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Multilingual Text Summarizer\")\n",
    "\n",
    "# Text Input\n",
    "tk.Label(root, text=\"Input Text:\").pack(pady=5)\n",
    "text_input = scrolledtext.ScrolledText(root, height=10, width=60)\n",
    "text_input.pack(pady=5)\n",
    "\n",
    "# Number of Sentences\n",
    "tk.Label(root, text=\"Number of Sentences:\").pack(pady=5)\n",
    "sentence_input = tk.Entry(root)\n",
    "sentence_input.pack(pady=5)\n",
    "sentence_input.insert(tk.END, '2')\n",
    "\n",
    "# Summarization Method Selection\n",
    "tk.Label(root, text=\"Choose Summarization Method:\").pack(pady=5)\n",
    "method_var = tk.StringVar(value=\"LSA\")\n",
    "methods = [\"LSA\", \"TF-IDF\", \"Frequency-Based\", \"Length-Based\"]\n",
    "for method in methods:\n",
    "    tk.Radiobutton(root, text=method, variable=method_var, value=method).pack(pady=2)\n",
    "\n",
    "# Summarize Button\n",
    "summarize_button = tk.Button(root, text=\"Summarize\", command=summarize_text)\n",
    "summarize_button.pack(pady=10)\n",
    "\n",
    "# Check Score Button\n",
    "check_score_button = tk.Button(root, text=\"Check ROUGE Score\", command=check_score)\n",
    "check_score_button.pack(pady=10)\n",
    "\n",
    "# Compare Scores Button\n",
    "compare_scores_button = tk.Button(root, text=\"Compare All Scores\", command=compare_scores)\n",
    "compare_scores_button.pack(pady=10)\n",
    "\n",
    "# Text Output\n",
    "tk.Label(root, text=\"Summary:\").pack(pady=5)\n",
    "text_output = scrolledtext.ScrolledText(root, height=10, width=60)\n",
    "text_output.pack(pady=5)\n",
    "\n",
    "# Dictionary to hold summaries\n",
    "summaries = {}\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3c488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a6b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddfb060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faee53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e5068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
